{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efbb0a2-412e-4e05-84b2-3d765d8cbff2",
   "metadata": {},
   "source": [
    "## ingest\n",
    "Trying to figure out how to run butler.ingest() - ticket https://jira.lsstcorp.org/browse/DM-41032https://jira.lsstcorp.org/browse/DM-41032 - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acf812-bf1c-44a9-af08-14380357ef78",
   "metadata": {},
   "source": [
    "We need to ingest the data manually for the raws and they are going to a different destination, which we'll need to look up the URI to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead4d13-6fd9-4d96-8970-8f0c303523d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T21:16:24.040546Z",
     "iopub.status.busy": "2023-10-18T21:16:24.040364Z",
     "iopub.status.idle": "2023-10-18T21:16:24.043568Z",
     "shell.execute_reply": "2023-10-18T21:16:24.043081Z",
     "shell.execute_reply.started": "2023-10-18T21:16:24.040532Z"
    },
    "tags": []
   },
   "source": [
    "They are going here: /sdf/data/rubin/lsstdata/offline/instrument/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed9c8f-f1cc-49fb-9ed3-b217e90cc59a",
   "metadata": {},
   "source": [
    "We'll then need to grab the remaining path to be:\n",
    "butler.getURI(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9204c-eee4-475c-8f45-5fb7e5091dc8",
   "metadata": {},
   "source": [
    "The transfer should be able to be performed using lsst.resources.ResourcePath.transfer_from. After that, the ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8303d86-2b4b-4a9e-b267-8405ff762f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:47.929068Z",
     "iopub.status.busy": "2023-11-16T17:59:47.928830Z",
     "iopub.status.idle": "2023-11-16T17:59:47.931486Z",
     "shell.execute_reply": "2023-11-16T17:59:47.931074Z",
     "shell.execute_reply.started": "2023-11-16T17:59:47.929052Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b73659-0460-4116-8ba8-275c76f49bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:47.932525Z",
     "iopub.status.busy": "2023-11-16T17:59:47.932368Z",
     "iopub.status.idle": "2023-11-16T17:59:48.415753Z",
     "shell.execute_reply": "2023-11-16T17:59:48.415290Z",
     "shell.execute_reply.started": "2023-11-16T17:59:47.932512Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import astropy.time\n",
    "import lsst\n",
    "import lsst.daf.butler\n",
    "from lsst.daf.butler import Butler, Timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a7f16c-cd6f-4102-82b1-5b26a9ca963d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:48.416395Z",
     "iopub.status.busy": "2023-11-16T17:59:48.416268Z",
     "iopub.status.idle": "2023-11-16T17:59:48.418525Z",
     "shell.execute_reply": "2023-11-16T17:59:48.418191Z",
     "shell.execute_reply.started": "2023-11-16T17:59:48.416382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.utils.logging import VERBOSE, getLogger\n",
    "_LOG = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56dd7b2b-b28f-4c42-b04f-146fed6946d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:48.419112Z",
     "iopub.status.busy": "2023-11-16T17:59:48.418991Z",
     "iopub.status.idle": "2023-11-16T17:59:48.422933Z",
     "shell.execute_reply": "2023-11-16T17:59:48.422609Z",
     "shell.execute_reply.started": "2023-11-16T17:59:48.419100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.daf.butler import CollectionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3aaae203-69f0-4dcc-a184-b99fa224e596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:12:00.413481Z",
     "iopub.status.busy": "2023-11-16T19:12:00.413305Z",
     "iopub.status.idle": "2023-11-16T19:12:00.416001Z",
     "shell.execute_reply": "2023-11-16T19:12:00.415665Z",
     "shell.execute_reply.started": "2023-11-16T19:12:00.413469Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from lsst.daf.butler import (\n",
    "    DataCoordinate,\n",
    "    DataId,\n",
    "    DataIdValue,\n",
    "    Dimension,\n",
    "    DimensionElement,\n",
    "    DimensionRecord,\n",
    "    DimensionUniverse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6c07dfc-c94a-45c8-9615-1547831d08ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:48.424057Z",
     "iopub.status.busy": "2023-11-16T17:59:48.423865Z",
     "iopub.status.idle": "2023-11-16T17:59:51.123001Z",
     "shell.execute_reply": "2023-11-16T17:59:51.122531Z",
     "shell.execute_reply.started": "2023-11-16T17:59:48.424045Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "butler = Butler('/repo/embargo')\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd18f2b-fc22-4772-b6a1-0843b874cdfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.123764Z",
     "iopub.status.busy": "2023-11-16T17:59:51.123630Z",
     "iopub.status.idle": "2023-11-16T17:59:51.210820Z",
     "shell.execute_reply": "2023-11-16T17:59:51.210420Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.123750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dest_butler = Butler('/home/r/rnevin/scratch', writeable=True)\n",
    "dest_butler = Butler('/home/j/jarugula/scratch_butler', writeable=True)\n",
    "dest_registry = dest_butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59219d09-b22a-4d50-b7ce-4bf645265838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.211544Z",
     "iopub.status.busy": "2023-11-16T17:59:51.211416Z",
     "iopub.status.idle": "2023-11-16T17:59:51.213601Z",
     "shell.execute_reply": "2023-11-16T17:59:51.213245Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.211532Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasettype = 'raw'\n",
    "collections = 'LATISS/raw/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197ace89-dca9-4b07-9935-bb88f1a7b847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.214194Z",
     "iopub.status.busy": "2023-11-16T17:59:51.214069Z",
     "iopub.status.idle": "2023-11-16T17:59:51.225654Z",
     "shell.execute_reply": "2023-11-16T17:59:51.225292Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.214175Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = astropy.time.Time.now().tai\n",
    "embargo_hours = 80.0\n",
    "embargo_period = astropy.time.TimeDelta(\n",
    "        embargo_hours * 3600.0, format=\"sec\"\n",
    "    )\n",
    "timespan_embargo = Timespan(now - embargo_period, None)\n",
    "# timespan_embargo = Timespan(now - embargo_period, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5933e370-49f6-4dc8-b9a8-dfd4902decda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.226331Z",
     "iopub.status.busy": "2023-11-16T17:59:51.226121Z",
     "iopub.status.idle": "2023-11-16T17:59:51.228825Z",
     "shell.execute_reply": "2023-11-16T17:59:51.228447Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.226319Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure)\n"
     ]
    }
   ],
   "source": [
    "for dt in sorted(registry.queryDatasetTypes(datasettype)):\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a035355-115a-476f-8906-dbb95c57ae8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.229454Z",
     "iopub.status.busy": "2023-11-16T17:59:51.229325Z",
     "iopub.status.idle": "2023-11-16T17:59:51.231558Z",
     "shell.execute_reply": "2023-11-16T17:59:51.231197Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.229443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, dt in enumerate(registry.queryDimensionRecords('exposure',datasets=datasettype, collections=collections,\n",
    "#                                              )):\n",
    "#     print(dt)\n",
    "#     if i > 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95761562-87a8-430a-af06-43e8926a75fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:51.232176Z",
     "iopub.status.busy": "2023-11-16T17:59:51.232064Z",
     "iopub.status.idle": "2023-11-16T17:59:53.913383Z",
     "shell.execute_reply": "2023-11-16T17:59:53.912852Z",
     "shell.execute_reply.started": "2023-11-16T17:59:51.232166Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022083100004, 2022083100005]\n"
     ]
    }
   ],
   "source": [
    "dataId = {\"instrument\": \"LATISS\"}\n",
    "outside_embargo = [\n",
    "        dt.id\n",
    "        for dt in registry.queryDimensionRecords(\n",
    "            \"exposure\",\n",
    "            dataId=dataId,\n",
    "            datasets=datasettype,\n",
    "            collections=collections,\n",
    "            where=\"NOT exposure.timespan OVERLAPS\\\n",
    "                                                    timespan_embargo\",\n",
    "            bind={\"timespan_embargo\": timespan_embargo},\n",
    "        )\n",
    "    ][0:2]\n",
    "print(outside_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9f8ad1-cf0b-41c8-b97c-72c8273ee225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:53.914175Z",
     "iopub.status.busy": "2023-11-16T17:59:53.914027Z",
     "iopub.status.idle": "2023-11-16T17:59:53.928550Z",
     "shell.execute_reply": "2023-11-16T17:59:53.928196Z",
     "shell.execute_reply.started": "2023-11-16T17:59:53.914161Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query the DataIds after embargo period\n",
    "datasetRefs = registry.queryDatasets(\n",
    "    datasettype,\n",
    "    dataId=dataId,\n",
    "    collections=collections,\n",
    "    where=\"exposure.id IN (exposure_ids)\",\n",
    "    bind={\"exposure_ids\": outside_embargo},\n",
    ")#.expanded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e874080a-9669-4f9a-929f-d4803f22fdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:53.929108Z",
     "iopub.status.busy": "2023-11-16T17:59:53.928994Z",
     "iopub.status.idle": "2023-11-16T17:59:53.943016Z",
     "shell.execute_reply": "2023-11-16T17:59:53.942666Z",
     "shell.execute_reply.started": "2023-11-16T17:59:53.929098Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...} [sc=Exposure] (run=LATISS/raw/all id=cfd59ff4-4991-5093-b499-b3aff2d2089c)\n",
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...} [sc=Exposure] (run=LATISS/raw/all id=d8975b39-6873-53e0-aa7f-d8781ceaaec7)\n"
     ]
    }
   ],
   "source": [
    "for ref in datasetRefs:\n",
    "    print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e5b2043-da77-465c-b827-23eb94334186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:53.944942Z",
     "iopub.status.busy": "2023-11-16T17:59:53.944819Z",
     "iopub.status.idle": "2023-11-16T17:59:53.993814Z",
     "shell.execute_reply": "2023-11-16T17:59:53.993286Z",
     "shell.execute_reply.started": "2023-11-16T17:59:53.944931Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_prefix = '/home/j/jarugula/dest_uri' \n",
    "os.system('rm -rf '+dest_prefix)\n",
    "os.system('mkdir '+dest_prefix)\n",
    "dest_uri = lsst.resources.ResourcePath(dest_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae14f7e7-2e1c-4373-a485-73396c1ffa17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:53.994563Z",
     "iopub.status.busy": "2023-11-16T17:59:53.994435Z",
     "iopub.status.idle": "2023-11-16T17:59:53.997603Z",
     "shell.execute_reply": "2023-11-16T17:59:53.997131Z",
     "shell.execute_reply.started": "2023-11-16T17:59:53.994549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResourcePath(\"file:///home/j/jarugula/dest_uri/\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a14050c8-a4a3-4c08-b6ff-20e6b137e771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:53.998186Z",
     "iopub.status.busy": "2023-11-16T17:59:53.998066Z",
     "iopub.status.idle": "2023-11-16T17:59:54.013288Z",
     "shell.execute_reply": "2023-11-16T17:59:54.012903Z",
     "shell.execute_reply.started": "2023-11-16T17:59:53.998169Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}, run='LATISS/raw/all', id=cfd59ff4-4991-5093-b499-b3aff2d2089c): DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), {}), DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, run='LATISS/raw/all', id=d8975b39-6873-53e0-aa7f-d8781ceaaec7): DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"), {})}\n"
     ]
    }
   ],
   "source": [
    "source_uri = butler.get_many_uris(datasetRefs)\n",
    "#source_uri = butler.getURI(datasetRefs)\n",
    "print(source_uri)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e26dbc9c-5180-403c-bfac-f0a347ce1315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T01:53:04.272581Z",
     "iopub.status.busy": "2023-11-11T01:53:04.272397Z",
     "iopub.status.idle": "2023-11-11T01:53:04.415622Z",
     "shell.execute_reply": "2023-11-11T01:53:04.415283Z",
     "shell.execute_reply.started": "2023-11-11T01:53:04.272569Z"
    },
    "tags": []
   },
   "source": [
    "for (key, value) in source_uri.items():\n",
    "    print(key)\n",
    "    # print(value.count)\n",
    "    # print(value.index)\n",
    "    source_path_uri = value[0]\n",
    "    print(source_path_uri)\n",
    "    print(source_path_uri.exists())\n",
    "    source_path = value[0].path.strip('/')\n",
    "    print(source_path)\n",
    "    print(value[0].relative_to(value[0].root_uri()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88820e5-3b24-4600-bcdb-ba1253da2927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.013878Z",
     "iopub.status.busy": "2023-11-16T17:59:54.013761Z",
     "iopub.status.idle": "2023-11-16T17:59:54.256544Z",
     "shell.execute_reply": "2023-11-16T17:59:54.256088Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.013868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "True\n",
      "LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "file:///home/j/jarugula/dest_uri/\n",
      "file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "True\n",
      "LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "file:///home/j/jarugula/dest_uri/\n",
      "file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n"
     ]
    }
   ],
   "source": [
    "filedataset_list = []\n",
    "for (key, value) in source_uri.items():\n",
    "    # print(key)\n",
    "    # print(value.count)\n",
    "    # print(value.index)\n",
    "    source_path_uri = value[0]\n",
    "    print(source_path_uri)\n",
    "    print(source_path_uri.exists())\n",
    "    # source_path = value[0].path.strip('/')\n",
    "    source_path = source_path_uri.relative_to(value[0].root_uri())\n",
    "    print(source_path)\n",
    "    print(dest_uri)\n",
    "    new_dest_uri = dest_uri.join(source_path)\n",
    "    print(new_dest_uri)\n",
    "    \n",
    "    # transfer \n",
    "    new_dest_uri.transfer_from(source_path_uri, transfer='copy')\n",
    "    \n",
    "    # make filedatasets for ingest\n",
    "    filedataset_list.append(lsst.daf.butler.FileDataset(new_dest_uri, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afc3dfbd-5e25-413b-96d5-53c3ad7a5da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.257261Z",
     "iopub.status.busy": "2023-11-16T17:59:54.257127Z",
     "iopub.status.idle": "2023-11-16T17:59:54.260094Z",
     "shell.execute_reply": "2023-11-16T17:59:54.259759Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.257248Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileDataset(refs=[DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}, run='LATISS/raw/all', id=cfd59ff4-4991-5093-b499-b3aff2d2089c)], path=ResourcePath(\"file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), formatter=None),\n",
       " FileDataset(refs=[DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, run='LATISS/raw/all', id=d8975b39-6873-53e0-aa7f-d8781ceaaec7)], path=ResourcePath(\"file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"), formatter=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filedataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31301ee3-89f9-4eed-ab20-edde99f87617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.260673Z",
     "iopub.status.busy": "2023-11-16T17:59:54.260557Z",
     "iopub.status.idle": "2023-11-16T17:59:54.262824Z",
     "shell.execute_reply": "2023-11-16T17:59:54.262507Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.260662Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# register datatype to the destination\n",
    "# frombutler_datasettype = registry.getDatasetType('raw')\n",
    "# dest_registry.registerDatasetType(frombutler_datasettype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b8dafbb-f163-42f8-b50a-73e8ee698efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.263408Z",
     "iopub.status.busy": "2023-11-16T17:59:54.263297Z",
     "iopub.status.idle": "2023-11-16T17:59:54.267663Z",
     "shell.execute_reply": "2023-11-16T17:59:54.267345Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.263398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collection_chain = registry.getCollectionSummary(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c72b85d-acfa-4fa5-982b-b47045f88fe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.268236Z",
     "iopub.status.busy": "2023-11-16T17:59:54.268120Z",
     "iopub.status.idle": "2023-11-16T17:59:54.270502Z",
     "shell.execute_reply": "2023-11-16T17:59:54.270182Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.268225Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collection_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0922057a-af9c-4537-b562-3b16003d1793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.271030Z",
     "iopub.status.busy": "2023-11-16T17:59:54.270924Z",
     "iopub.status.idle": "2023-11-16T17:59:54.275374Z",
     "shell.execute_reply": "2023-11-16T17:59:54.275047Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.271020Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dest_registry.registerCollection('LATISS/raw/all', CollectionType(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0595c9d9-5634-42b3-b473-56e14f6c7676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:33:08.884647Z",
     "iopub.status.busy": "2023-11-16T19:33:08.884374Z",
     "iopub.status.idle": "2023-11-16T19:33:08.887721Z",
     "shell.execute_reply": "2023-11-16T19:33:08.887356Z",
     "shell.execute_reply.started": "2023-11-16T19:33:08.884633Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CollectionType.RUN: 1>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registry.getCollectionType(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "90101ef5-5137-452a-8e96-d2fb6afa5955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:41:55.020364Z",
     "iopub.status.busy": "2023-11-16T19:41:55.020150Z",
     "iopub.status.idle": "2023-11-16T19:41:55.029308Z",
     "shell.execute_reply": "2023-11-16T19:41:55.028996Z",
     "shell.execute_reply.started": "2023-11-16T19:41:55.020349Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATISS/raw/all\n",
      "1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "source_collection = set()\n",
    "for ref in source_refs:\n",
    "    source_collection.add(ref.run)\n",
    "        \n",
    "for collection in source_collection:\n",
    "    print(collection)\n",
    "    print(registry.getCollectionType(collection))\n",
    "    print(registry.getCollectionSummary(collection) == registry.getCollectionSummary(collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3eb442cc-f2a6-4e92-b517-58b19d4c1007",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:59:54.275924Z",
     "iopub.status.busy": "2023-11-16T17:59:54.275816Z",
     "iopub.status.idle": "2023-11-16T17:59:54.282207Z",
     "shell.execute_reply": "2023-11-16T17:59:54.281859Z",
     "shell.execute_reply.started": "2023-11-16T17:59:54.275914Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure)\n",
      "DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure)\n"
     ]
    }
   ],
   "source": [
    "for ref in datasetRefs:\n",
    "    print(ref.datasetType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "536e2686-62af-4a41-b43d-68d2959de827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:23:51.749606Z",
     "iopub.status.busy": "2023-11-16T19:23:51.749419Z",
     "iopub.status.idle": "2023-11-16T19:23:51.754440Z",
     "shell.execute_reply": "2023-11-16T19:23:51.754052Z",
     "shell.execute_reply.started": "2023-11-16T19:23:51.749594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LATISS/raw/all\n",
      "LATISS/raw/all\n"
     ]
    }
   ],
   "source": [
    "for ref in datasetRefs:\n",
    "        print(ref.run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ea3efce-6fd0-4497-8f48-0e5bd6b71114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:12:46.343226Z",
     "iopub.status.busy": "2023-11-16T19:12:46.342933Z",
     "iopub.status.idle": "2023-11-16T19:12:46.345615Z",
     "shell.execute_reply": "2023-11-16T19:12:46.345245Z",
     "shell.execute_reply.started": "2023-11-16T19:12:46.343212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_refs = datasetRefs\n",
    "source_butler = butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdc551bc-c8f0-4b0f-b7e8-ef49a0d8d9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:44:56.600033Z",
     "iopub.status.busy": "2023-11-16T19:44:56.599841Z",
     "iopub.status.idle": "2023-11-16T19:44:56.607981Z",
     "shell.execute_reply": "2023-11-16T19:44:56.607661Z",
     "shell.execute_reply.started": "2023-11-16T19:44:56.600019Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_for_ingest(target_registry, target_butler, \n",
    "                    source_registry, source_butler, \n",
    "                    source_refs, \n",
    "                    register_dataset_types = True, \n",
    "                    register_collection = True,\n",
    "                    transfer_dimensions=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    this code is taken from: \n",
    "    https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py\n",
    "    L1920-L1949\n",
    "    \n",
    "    This code registers DatasetType and collection to the target_butler.\n",
    "    Does not register instrument\n",
    "    \n",
    "    Run this code before ingest\n",
    "    \"\"\"\n",
    "    \n",
    "    # register datasetType\n",
    "    source_dataset_types = set()\n",
    "    for ref in source_refs:\n",
    "        source_dataset_types.add(ref.datasetType)\n",
    "        \n",
    "    newly_registered_dataset_types = set() \n",
    "    for datasetType in source_dataset_types:\n",
    "        if register_dataset_types:\n",
    "            if target_registry.registerDatasetType(datasetType):\n",
    "                newly_registered_dataset_types.add(datasetType)\n",
    "        else:\n",
    "            # If the dataset type is missing, let it fail immediately.\n",
    "            target_dataset_type = target_registry.getDatasetType(datasetType.name)\n",
    "            # print(target_dataset_type)\n",
    "            if target_dataset_type != datasetType:\n",
    "                raise ConflictingDefinitionError(\n",
    "                    \"Source butler dataset type differs from definition\"\n",
    "                    f\" in target butler: {datasetType} !=\"\n",
    "                    f\" {target_dataset_type}\"\n",
    "                )\n",
    "                \n",
    "    if newly_registered_dataset_types:\n",
    "        print( \"Registered the following dataset types in the target Butler: \",\n",
    "              \", \".join(d.name for d in newly_registered_dataset_types),\n",
    "             )\n",
    "    else:\n",
    "        print(\"All required dataset types are known to the target Butler\")\n",
    "        \n",
    "    # register collection\n",
    "    # This is written only for run collection\n",
    "    source_collection = set()\n",
    "    for ref in source_refs:\n",
    "        source_collection.add(ref.run)\n",
    "        \n",
    "    newly_registered_collection = set() \n",
    "    for collection in source_collection:\n",
    "        if register_collection:\n",
    "            collection_type = source_registry.getCollectionType(collection)\n",
    "            if target_registry.registerCollection(collection, CollectionType(collection_type)):\n",
    "                newly_registered_collection.add(collection)\n",
    "                \n",
    "        else:\n",
    "            target_collection = target_registry.getCollectionSummary(collection)\n",
    "            if target_collection != registry.getCollectionSummary(collection):\n",
    "                raise ConflictingDefinitionError(\n",
    "                    \"Source butler collection differs from definition\"\n",
    "                    f\" in target butler: {collection} !=\"\n",
    "                    f\" {target_collection}\"\n",
    "                )\n",
    "                \n",
    "    print(newly_registered_collection)\n",
    "                \n",
    "    if newly_registered_collection:\n",
    "        print( \"Registered the following collection in the target Butler: \",\n",
    "              \", \".join(collection for collection in newly_registered_collection),\n",
    "             )\n",
    "    else:\n",
    "        print(\"All required collections are known to the target Butler\")\n",
    "    \n",
    "        \n",
    "    dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "    if transfer_dimensions:\n",
    "        elements = frozenset(\n",
    "                element\n",
    "                for element in target_butler.dimensions.getStaticElements()\n",
    "                if element.hasTable() and element.viewOf is None\n",
    "            )\n",
    "        dataIds = {ref.dataId for ref in source_refs}\n",
    "        \n",
    "        for dataId in dataIds:\n",
    "            if not dataId.hasRecords():\n",
    "                if registry := getattr(source_butler, \"registry\", None):\n",
    "                    dataId = registry.expandDataId(dataId)\n",
    "                else:\n",
    "                    raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "            for record in dataId.records.values():\n",
    "                if record is not None and record.definition in elements:\n",
    "                    dimension_records[record.definition].setdefault(record.dataId, record)\n",
    "                    \n",
    "        print('dimension records after', dimension_records)\n",
    "        \n",
    "        print(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "        for element, r in dimension_records.items():\n",
    "            records = [r[dataId] for dataId in r]\n",
    "            dest_butler._registry.insertDimensionData(element, *records, skip_existing=True)\n",
    "        \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3085589b-389b-47f7-ad77-893a8734a80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:44:57.550456Z",
     "iopub.status.busy": "2023-11-16T19:44:57.550177Z",
     "iopub.status.idle": "2023-11-16T19:44:57.557296Z",
     "shell.execute_reply": "2023-11-16T19:44:57.556992Z",
     "shell.execute_reply.started": "2023-11-16T19:44:57.550441Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required dataset types are known to the target Butler\n",
      "set()\n",
      "All required collections are known to the target Butler\n"
     ]
    }
   ],
   "source": [
    "_ = prep_for_ingest(dest_registry, dest_butler, \n",
    "                    registry, butler, \n",
    "                    datasetRefs,\n",
    "                    register_dataset_types = False, \n",
    "                    register_collection = True,\n",
    "                    transfer_dimensions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2090c-51ec-48d7-a012-9846a9c5ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ingest to the destination butler\n",
    "dest_butler.ingest(*filedataset_list, transfer = 'direct')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45ea5354-3403-4010-9d42-5a560c4ef494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:19:40.850727Z",
     "iopub.status.busy": "2023-11-16T17:19:40.850443Z",
     "iopub.status.idle": "2023-11-16T17:19:41.017182Z",
     "shell.execute_reply": "2023-11-16T17:19:41.016716Z",
     "shell.execute_reply.started": "2023-11-16T17:19:40.850714Z"
    },
    "tags": []
   },
   "source": [
    "# before we can run ingest, we need to register everything:\n",
    "# this code is taken from: https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py#L1920-L1949\n",
    "\n",
    "# Check to see if the dataset type in the source butler has\n",
    "# the same definition in the target butler and register missing\n",
    "# ones if requested. Registration must happen outside a transaction.\n",
    "newly_registered_dataset_types = set()\n",
    "for datasetType in source_dataset_types:\n",
    "    if register_dataset_types:\n",
    "        # Let this raise immediately if inconsistent. Continuing\n",
    "        # on to find additional inconsistent dataset types\n",
    "        # might result in additional unwanted dataset types being\n",
    "        # registered.\n",
    "        if dest_registry.registerDatasetType(datasetType):\n",
    "            newly_registered_dataset_types.add(datasetType)\n",
    "    else:\n",
    "        # If the dataset type is missing, let it fail immediately.\n",
    "        target_dataset_type = dest_registry.getDatasetType(datasetType.name)\n",
    "        if target_dataset_type != datasetType:\n",
    "            raise ConflictingDefinitionError(\n",
    "                \"Source butler dataset type differs from definition\"\n",
    "                f\" in target butler: {datasetType} !=\"\n",
    "                f\" {target_dataset_type}\"\n",
    "            )\n",
    "if newly_registered_dataset_types:\n",
    "    # We may have registered some even if there were inconsistencies\n",
    "    # but should let people know (or else remove them again).\n",
    "    _LOG.verbose(\n",
    "        \"Registered the following dataset types in the target Butler: %s\",\n",
    "        \", \".join(d.name for d in newly_registered_dataset_types),\n",
    "    )\n",
    "else:\n",
    "    _LOG.verbose(\"All required dataset types are known to the target Butler\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5caa1b31-9393-434e-9b12-6523b43e713e",
   "metadata": {},
   "source": [
    "# and this is from https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py#L1951-L1975\n",
    "dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "if transfer_dimensions:\n",
    "    # Collect all the dimension records for these refs.\n",
    "    # All dimensions are to be copied but the list of valid dimensions\n",
    "    # come from this butler's universe.\n",
    "    elements = frozenset(\n",
    "        element\n",
    "        for element in self.dimensions.getStaticElements()\n",
    "        if element.hasTable() and element.viewOf is None\n",
    "    )\n",
    "    dataIds = {ref.dataId for ref in source_refs}\n",
    "    # This logic comes from saveDataIds.\n",
    "    for dataId in dataIds:\n",
    "        # Need an expanded record, if not expanded that we need a full\n",
    "        # butler with registry (allow mocks with registry too).\n",
    "        if not dataId.hasRecords():\n",
    "            if registry := getattr(source_butler, \"registry\", None):\n",
    "                dataId = registry.expandDataId(dataId)\n",
    "            else:\n",
    "                raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "        # If this butler doesn't know about a dimension in the source\n",
    "        # butler things will break later.\n",
    "        for record in dataId.records.values():\n",
    "            if record is not None and record.definition in elements:\n",
    "                dimension_records[record.definition].setdefault(record.dataId, record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afc89b46-35a6-49e1-9ae0-18c8bd81ae2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:52:57.002986Z",
     "iopub.status.busy": "2023-11-15T17:52:57.002669Z",
     "iopub.status.idle": "2023-11-15T17:52:57.017938Z",
     "shell.execute_reply": "2023-11-15T17:52:57.017517Z",
     "shell.execute_reply.started": "2023-11-15T17:52:57.002973Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension records before defaultdict(<class 'dict'>, {})\n",
      "frozenset({DatabaseDimension(exposure), DatabaseDimension(subfilter), DatabaseDimension(patch), DatabaseDimensionCombination(visit_system_membership), DatabaseDimension(detector), DatabaseDimension(tract), GovernorDimension(instrument), DatabaseDimension(physical_filter), DatabaseDimensionCombination(visit_detector_region), GovernorDimension(skymap), DatabaseDimension(visit), DatabaseDimensionCombination(visit_definition), DatabaseDimension(visit_system)})\n",
      "dataIds {{instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}}\n",
      "dimension records after defaultdict(<class 'dict'>, {GovernorDimension(instrument): {{instrument: 'LATISS'}: instrument.RecordClass(name='LATISS', visit_max=6050123199999, visit_system=2, exposure_max=6050123199999, detector_max=1, class_name='lsst.obs.lsst.Latiss')}, DatabaseDimension(detector): {{instrument: 'LATISS', detector: 0}: detector.RecordClass(instrument='LATISS', id=0, full_name='RXX_S00', name_in_raft='RXX_S00', raft=None, purpose='SCIENCE')}, DatabaseDimension(physical_filter): {{instrument: 'LATISS', physical_filter: 'unknown~unknown'}: physical_filter.RecordClass(instrument='LATISS', name='unknown~unknown', band='unknown')}, DatabaseDimension(exposure): {{instrument: 'LATISS', exposure: 2022083100005}: exposure.RecordClass(instrument='LATISS', id=2022083100005, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000005', exposure_time=0.0, dark_time=0.011363, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=5, seq_start=5, seq_end=5, group_name='2022083100005', group_id=2022083100005, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:59:03.162020', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:59:03.173000', scale='tai', format='iso'))), {instrument: 'LATISS', exposure: 2022083100004}: exposure.RecordClass(instrument='LATISS', id=2022083100004, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000004', exposure_time=0.0, dark_time=0.0160482, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=4, seq_start=4, seq_end=4, group_name='2022083100004', group_id=2022083100004, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:58:13.633984', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:58:13.650000', scale='tai', format='iso')))}})\n"
     ]
    }
   ],
   "source": [
    "# re-defining stuff to align with the butler code:\n",
    "source_refs = datasetRefs\n",
    "source_butler = butler\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from lsst.daf.butler import (\n",
    "    DataCoordinate,\n",
    "    DataId,\n",
    "    DataIdValue,\n",
    "    Dimension,\n",
    "    DimensionElement,\n",
    "    DimensionRecord,\n",
    "    DimensionUniverse,\n",
    ")\n",
    "\n",
    "dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "print('dimension records before', dimension_records)\n",
    "\n",
    "elements = frozenset(\n",
    "                element\n",
    "                for element in dest_butler.dimensions.getStaticElements()\n",
    "                if element.hasTable() and element.viewOf is None\n",
    "            )\n",
    "print(elements)\n",
    "\n",
    "dataIds = {ref.dataId for ref in source_refs}\n",
    "print('dataIds', dataIds)\n",
    "\n",
    "# This logic comes from saveDataIds.\n",
    "for dataId in dataIds:\n",
    "    # Need an expanded record, if not expanded that we need a full\n",
    "    # butler with registry (allow mocks with registry too).\n",
    "    if not dataId.hasRecords():\n",
    "        if registry := getattr(source_butler, \"registry\", None):\n",
    "            dataId = registry.expandDataId(dataId)\n",
    "        else:\n",
    "            raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "    # If this butler doesn't know about a dimension in the source\n",
    "    # butler things will break later.\n",
    "    for record in dataId.records.values():\n",
    "        if record is not None and record.definition in elements:\n",
    "            dimension_records[record.definition].setdefault(record.dataId, record)\n",
    "print('dimension records after', dimension_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b3da80b-760e-4040-8625-c0f18090fd37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:55:09.260680Z",
     "iopub.status.busy": "2023-11-15T17:55:09.260235Z",
     "iopub.status.idle": "2023-11-15T17:55:09.293103Z",
     "shell.execute_reply": "2023-11-15T17:55:09.292722Z",
     "shell.execute_reply.started": "2023-11-15T17:55:09.260663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring that dimension records exist for transferred datasets.\n"
     ]
    }
   ],
   "source": [
    "# now actually do the mod of dimension records\n",
    "if dimension_records:\n",
    "    #_LOG.verbose(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "    print(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "    for element, r in dimension_records.items():\n",
    "        records = [r[dataId] for dataId in r]\n",
    "        # Assume that if the record is already present that we can\n",
    "        # use it without having to check that the record metadata\n",
    "        # is consistent.\n",
    "        dest_butler._registry.insertDimensionData(element, *records, skip_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ce27fd3-1135-4974-b524-c73d02cc7ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:45:09.395146Z",
     "iopub.status.busy": "2023-11-16T19:45:09.394859Z",
     "iopub.status.idle": "2023-11-16T19:45:09.403982Z",
     "shell.execute_reply": "2023-11-16T19:45:09.403605Z",
     "shell.execute_reply.started": "2023-11-16T19:45:09.395130Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lsst.daf.butler._registry_shim.RegistryShim object at 0x7f361a038490>\n",
      "results [exposure.RecordClass(instrument='LATISS', id=2022083100005, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000005', exposure_time=0.0, dark_time=0.011363, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=5, seq_start=5, seq_end=5, group_name='2022083100005', group_id=2022083100005, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:59:03.162020', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:59:03.173000', scale='tai', format='iso'))), exposure.RecordClass(instrument='LATISS', id=2022083100004, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000004', exposure_time=0.0, dark_time=0.0160482, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=4, seq_start=4, seq_end=4, group_name='2022083100004', group_id=2022083100004, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:58:13.633984', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:58:13.650000', scale='tai', format='iso')))]\n"
     ]
    }
   ],
   "source": [
    "# test dimensionrecord\n",
    "print(dest_registry)\n",
    "\n",
    "results = dest_registry.queryDimensionRecords( 'exposure',\n",
    "                                                 collections='LATISS/raw/all',\n",
    "                                                 datasets='raw')\n",
    "results = list( set(results) )\n",
    "print('results', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eec2fd-ce6e-4f67-ac0f-9f092a778fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pipelines.lsst.io/v/daily/py-api/lsst.daf.butler.Registry.html#lsst.daf.butler.Registry.queryDimensionRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6567ea-1841-4c23-8c91-3eee86167920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T02:00:59.749863Z",
     "iopub.status.busy": "2023-11-11T02:00:59.749654Z",
     "iopub.status.idle": "2023-11-11T02:00:59.764222Z",
     "shell.execute_reply": "2023-11-11T02:00:59.763534Z",
     "shell.execute_reply.started": "2023-11-11T02:00:59.749847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RegistryShim.syncDimensionData() missing 2 required positional arguments: 'element' and 'row'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdest_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msyncDimensionData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: RegistryShim.syncDimensionData() missing 2 required positional arguments: 'element' and 'row'"
     ]
    }
   ],
   "source": [
    "dest_registry.syncDimensionData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a5a5a-46bc-439c-9e77-2d24d2c1c8b0",
   "metadata": {},
   "source": [
    "Use datasetRefs to look up the URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755761cb-01d7-4eed-84df-8d0c3ab6dbca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dest_uri.join(LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits)\n",
    "# dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "# dest_uri = dest_prefix + 'LATISS'\n",
    "# dest = Butler(dest_prefix, writeable=True)\n",
    "\n",
    "#dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02f1bbce-14e8-4a42-ae73-c8a88bc08697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:55:43.508351Z",
     "iopub.status.busy": "2023-10-23T20:55:43.508101Z",
     "iopub.status.idle": "2023-10-23T20:55:43.522877Z",
     "shell.execute_reply": "2023-10-23T20:55:43.522396Z",
     "shell.execute_reply.started": "2023-10-23T20:55:43.508336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...} [sc=Exposure] (run=LATISS/raw/all id=cfd59ff4-4991-5093-b499-b3aff2d2089c) value DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), {})\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetRefURIs' object has no attribute 'as_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m source_uri\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m, key,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, value)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_local\u001b[49m())\n\u001b[1;32m      5\u001b[0m STOP\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(source_uri\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetRefURIs' object has no attribute 'as_local'"
     ]
    }
   ],
   "source": [
    "#for i, (key, value) in enumerate(my_dict.items()):\n",
    "for (key, value) in source_uri.items():\n",
    "    print('key', key,'value', value)\n",
    "    print(value.as_local())\n",
    "    \n",
    "STOP\n",
    "print(source_uri.keys())\n",
    "print(source_uri[0].exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d2561-c6b0-4fb0-ab7c-8e300a9d8fd5",
   "metadata": {},
   "source": [
    "The below cell is failing because transfer_from is expecting a dict object from source_uri that has an as_local() element. When we obtain the source_uri list, there is an empty element for the component URI, but I'm not sure if this is the root of the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e7020e1-3da8-4665-a611-b56baf07d4f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:56:46.963550Z",
     "iopub.status.busy": "2023-10-23T20:56:46.963300Z",
     "iopub.status.idle": "2023-10-23T20:56:46.989140Z",
     "shell.execute_reply": "2023-10-23T20:56:46.988682Z",
     "shell.execute_reply.started": "2023-10-23T20:56:46.963537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'as_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we need dest_uri to not be a string\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# and to actually be \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdest_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransfer_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dest\u001b[38;5;241m.\u001b[39mingest(datasetRefs, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/resources/g24611a4c00+e358f92434/python/lsst/resources/file.py:169\u001b[0m, in \u001b[0;36mFileResourcePath.transfer_from\u001b[0;34m(self, src, transfer, overwrite, transaction)\u001b[0m\n\u001b[1;32m    158\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransferring \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [exists: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] -> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [exists: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] (transfer=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m         src,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         transfer,\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# We do not have to special case FileResourcePath here because\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# as_local handles that.\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_local\u001b[49m() \u001b[38;5;28;01mas\u001b[39;00m local_uri:\n\u001b[1;32m    170\u001b[0m     is_temporary \u001b[38;5;241m=\u001b[39m local_uri\u001b[38;5;241m.\u001b[39misTemporary\n\u001b[1;32m    171\u001b[0m     local_src \u001b[38;5;241m=\u001b[39m local_uri\u001b[38;5;241m.\u001b[39mospath\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'as_local'"
     ]
    }
   ],
   "source": [
    "\n",
    "# we need dest_uri to not be a string\n",
    "# and to actually be \n",
    "dest_uri.transfer_from(source_uri, transfer='copy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24ccd655-26e2-4845-b7cd-25eb934b75fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T21:07:40.021065Z",
     "iopub.status.busy": "2023-10-23T21:07:40.020888Z",
     "iopub.status.idle": "2023-10-23T21:07:40.045772Z",
     "shell.execute_reply": "2023-10-23T21:07:40.045285Z",
     "shell.execute_reply.started": "2023-10-23T21:07:40.021053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ParentDatasetQueryResults' object has no attribute 'refs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasetRefs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, mode = 'direct')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/daf_butler/gfc0b858265+07967ebf72/python/lsst/daf/butler/core/utils.py:61\u001b[0m, in \u001b[0;36mtransactional.<locals>.inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransaction():\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/daf_butler/gfc0b858265+07967ebf72/python/lsst/daf/butler/_butler.py:2023\u001b[0m, in \u001b[0;36mButler.ingest\u001b[0;34m(self, transfer, run, idGenerationMode, record_validation_info, *datasets)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mwrap(datasets, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrouping by dataset type\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;66;03m# Somewhere to store pre-existing refs if we have an\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m# execution butler.\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m     existingRefs: \u001b[38;5;28mlist\u001b[39m[DatasetRef] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2023\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m:\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m ref\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# For mypy\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m         group_key \u001b[38;5;241m=\u001b[39m (ref\u001b[38;5;241m.\u001b[39mdatasetType, ref\u001b[38;5;241m.\u001b[39mrun)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParentDatasetQueryResults' object has no attribute 'refs'"
     ]
    }
   ],
   "source": [
    "# next do ingest\n",
    "# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "dest.ingest(datasetRefs)#, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69081372-a768-47fc-b33b-8442c35360b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee2383-d431-44de-bb96-e4c0672eec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78d3e3-2a19-468b-9e97-c1da8eec6cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d99624d0-bfa9-404f-bc44-d4d827e9f0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:41:07.108669Z",
     "iopub.status.busy": "2023-10-20T19:41:07.108390Z",
     "iopub.status.idle": "2023-10-20T19:41:07.116799Z",
     "shell.execute_reply": "2023-10-20T19:41:07.116409Z",
     "shell.execute_reply.started": "2023-10-20T19:41:07.108655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lsst.resources.s3.S3ResourcePath'> s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "<class 'lsst.resources.s3.S3ResourcePath'> s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "[ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\")]\n"
     ]
    }
   ],
   "source": [
    "uri_list = []\n",
    "for i,ref in enumerate(datasetRefs):\n",
    "    #print(ref.dataId.full)\n",
    "    uri = butler.getURI(ref)\n",
    "    print(type(uri), uri)\n",
    "    uri_list.append(uri)\n",
    "print(uri_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5169df6-1325-4b31-b700-abea4b66f86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:33:26.604893Z",
     "iopub.status.busy": "2023-10-20T19:33:26.604486Z",
     "iopub.status.idle": "2023-10-20T19:33:26.691862Z",
     "shell.execute_reply": "2023-10-20T19:33:26.691507Z",
     "shell.execute_reply.started": "2023-10-20T19:33:26.604876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_prefix = '/home/r/rnevin/scratch'\n",
    "dest = Butler(dest_prefix, writeable=True)\n",
    "dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc7635d1-55b7-4cad-ac2c-3d53be37d02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:41:35.805930Z",
     "iopub.status.busy": "2023-10-20T19:41:35.805463Z",
     "iopub.status.idle": "2023-10-20T19:41:35.817273Z",
     "shell.execute_reply": "2023-10-20T19:41:35.816873Z",
     "shell.execute_reply.started": "2023-10-20T19:41:35.805915Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlsst\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#uri = \"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m uri_src \u001b[38;5;241m=\u001b[39m lsst\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mResourcePath\u001b[38;5;241m.\u001b[39mtransfer_from(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/repo/embargo/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muri_list\u001b[49m, transfer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(uri_src)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "import lsst\n",
    "#uri = \"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"\n",
    "uri_src = lsst.resources.ResourcePath.transfer_from('/repo/embargo/' + uri_list, transfer='copy')\n",
    "print(uri_src)\n",
    "\n",
    "# next do ingest\n",
    "# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "dest.ingest(uri_src, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1590869-08f7-4df3-9392-de63e03b655c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f50fd-e8ea-4fe6-9efd-abbf1da0ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#butler = Butler('/repo/embargo')\n",
    "#registry = butler.registry\n",
    "\n",
    "dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "\n",
    "dest = Butler(dest_prefix + uri, writeable=True)\n",
    "dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc0a5e-94dd-484d-8c2f-38aab292d79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7e21f7-e9f1-4ca8-8e46-e1edace8c0e4",
   "metadata": {},
   "source": [
    "lsst.resources.ResourcePath.transfer_from(src, transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bc56d-8c2e-479b-8dff-468f9290f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "\n",
    "dest = Butler(dest_prefix + uri, writeable=True)\n",
    "dest_registry = dest.registry\n",
    "\n",
    "for i,ref in enumerate(datasetRefs):\n",
    "    #print(ref.dataId.full)\n",
    "    uri = butler.getURI(ref)\n",
    "    print(uri)\n",
    "    # first do transfer_from\n",
    "    # https://pipelines.lsst.io/v/weekly/py-api/lsst.resources.ResourcePath.html\n",
    "    # actually, returns an URI with an updated final component of the source\n",
    "    uri_src = lsst.resources.ResourcePath.transfer_from('/repo/embargo/'+uri)\n",
    "\n",
    "    # next do ingest\n",
    "    # The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "    # https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "    dest.ingest(uri_src, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7b3b1-07e5-4418-90a2-38e81323b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dest.transfer_from(\n",
    "    butler,\n",
    "    source_refs=datasetRefs,\n",
    "    transfer=\"copy\",\n",
    "    skip_missing=True,\n",
    "    register_dataset_types=True,\n",
    "    transfer_dimensions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282eee-c95c-4815-ab52-28f1334fd53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
