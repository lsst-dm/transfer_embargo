{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efbb0a2-412e-4e05-84b2-3d765d8cbff2",
   "metadata": {},
   "source": [
    "## ingest\n",
    "Trying to figure out how to run butler.ingest() - ticket https://jira.lsstcorp.org/browse/DM-41032https://jira.lsstcorp.org/browse/DM-41032 - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acf812-bf1c-44a9-af08-14380357ef78",
   "metadata": {},
   "source": [
    "We need to ingest the data manually for the raws and they are going to a different destination, which we'll need to look up the URI to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead4d13-6fd9-4d96-8970-8f0c303523d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-18T21:16:24.040546Z",
     "iopub.status.busy": "2023-10-18T21:16:24.040364Z",
     "iopub.status.idle": "2023-10-18T21:16:24.043568Z",
     "shell.execute_reply": "2023-10-18T21:16:24.043081Z",
     "shell.execute_reply.started": "2023-10-18T21:16:24.040532Z"
    },
    "tags": []
   },
   "source": [
    "They are going here: /sdf/data/rubin/lsstdata/offline/instrument/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ed9c8f-f1cc-49fb-9ed3-b217e90cc59a",
   "metadata": {},
   "source": [
    "We'll then need to grab the remaining path to be:\n",
    "butler.getURI(dataset_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc9204c-eee4-475c-8f45-5fb7e5091dc8",
   "metadata": {},
   "source": [
    "The transfer should be able to be performed using lsst.resources.ResourcePath.transfer_from. After that, the ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8303d86-2b4b-4a9e-b267-8405ff762f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:47.600876Z",
     "iopub.status.busy": "2023-11-20T17:29:47.600642Z",
     "iopub.status.idle": "2023-11-20T17:29:47.603094Z",
     "shell.execute_reply": "2023-11-20T17:29:47.602740Z",
     "shell.execute_reply.started": "2023-11-20T17:29:47.600863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b73659-0460-4116-8ba8-275c76f49bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:47.603849Z",
     "iopub.status.busy": "2023-11-20T17:29:47.603735Z",
     "iopub.status.idle": "2023-11-20T17:29:48.086166Z",
     "shell.execute_reply": "2023-11-20T17:29:48.085744Z",
     "shell.execute_reply.started": "2023-11-20T17:29:47.603838Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import astropy.time\n",
    "import lsst\n",
    "import lsst.daf.butler\n",
    "from lsst.daf.butler import Butler, Timespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a7f16c-cd6f-4102-82b1-5b26a9ca963d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:48.086843Z",
     "iopub.status.busy": "2023-11-20T17:29:48.086706Z",
     "iopub.status.idle": "2023-11-20T17:29:48.088989Z",
     "shell.execute_reply": "2023-11-20T17:29:48.088635Z",
     "shell.execute_reply.started": "2023-11-20T17:29:48.086831Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.utils.logging import VERBOSE, getLogger\n",
    "_LOG = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56dd7b2b-b28f-4c42-b04f-146fed6946d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:48.089980Z",
     "iopub.status.busy": "2023-11-20T17:29:48.089858Z",
     "iopub.status.idle": "2023-11-20T17:29:48.093799Z",
     "shell.execute_reply": "2023-11-20T17:29:48.093466Z",
     "shell.execute_reply.started": "2023-11-20T17:29:48.089969Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lsst.daf.butler import CollectionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aaae203-69f0-4dcc-a184-b99fa224e596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:48.094379Z",
     "iopub.status.busy": "2023-11-20T17:29:48.094268Z",
     "iopub.status.idle": "2023-11-20T17:29:48.098388Z",
     "shell.execute_reply": "2023-11-20T17:29:48.098069Z",
     "shell.execute_reply.started": "2023-11-20T17:29:48.094368Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from lsst.daf.butler import (\n",
    "    DataCoordinate,\n",
    "    DataId,\n",
    "    DataIdValue,\n",
    "    Dimension,\n",
    "    DimensionElement,\n",
    "    DimensionRecord,\n",
    "    DimensionUniverse,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c07dfc-c94a-45c8-9615-1547831d08ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:48.098966Z",
     "iopub.status.busy": "2023-11-20T17:29:48.098854Z",
     "iopub.status.idle": "2023-11-20T17:29:50.533124Z",
     "shell.execute_reply": "2023-11-20T17:29:50.532670Z",
     "shell.execute_reply.started": "2023-11-20T17:29:48.098955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "butler = Butler('/repo/embargo')\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd18f2b-fc22-4772-b6a1-0843b874cdfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.533855Z",
     "iopub.status.busy": "2023-11-20T17:29:50.533731Z",
     "iopub.status.idle": "2023-11-20T17:29:50.612928Z",
     "shell.execute_reply": "2023-11-20T17:29:50.612537Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.533843Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dest_butler = Butler('/home/r/rnevin/scratch', writeable=True)\n",
    "dest_butler = Butler('/home/j/jarugula/scratch_butler', writeable=True)\n",
    "dest_registry = dest_butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59219d09-b22a-4d50-b7ce-4bf645265838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.613582Z",
     "iopub.status.busy": "2023-11-20T17:29:50.613462Z",
     "iopub.status.idle": "2023-11-20T17:29:50.615551Z",
     "shell.execute_reply": "2023-11-20T17:29:50.615208Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.613570Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasettype = 'raw'\n",
    "collections = 'LATISS/raw/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "197ace89-dca9-4b07-9935-bb88f1a7b847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.616141Z",
     "iopub.status.busy": "2023-11-20T17:29:50.616028Z",
     "iopub.status.idle": "2023-11-20T17:29:50.628666Z",
     "shell.execute_reply": "2023-11-20T17:29:50.628295Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.616130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "now = astropy.time.Time.now().tai\n",
    "embargo_hours = 80.0\n",
    "embargo_period = astropy.time.TimeDelta(\n",
    "        embargo_hours * 3600.0, format=\"sec\"\n",
    "    )\n",
    "timespan_embargo = Timespan(now - embargo_period, None)\n",
    "# timespan_embargo = Timespan(now - embargo_period, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5933e370-49f6-4dc8-b9a8-dfd4902decda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.630138Z",
     "iopub.status.busy": "2023-11-20T17:29:50.630017Z",
     "iopub.status.idle": "2023-11-20T17:29:50.632700Z",
     "shell.execute_reply": "2023-11-20T17:29:50.632329Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.630128Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure)\n"
     ]
    }
   ],
   "source": [
    "for dt in sorted(registry.queryDatasetTypes(datasettype)):\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a035355-115a-476f-8906-dbb95c57ae8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.633221Z",
     "iopub.status.busy": "2023-11-20T17:29:50.633113Z",
     "iopub.status.idle": "2023-11-20T17:29:50.635183Z",
     "shell.execute_reply": "2023-11-20T17:29:50.634830Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.633211Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, dt in enumerate(registry.queryDimensionRecords('exposure',datasets=datasettype, collections=collections,\n",
    "#                                              )):\n",
    "#     print(dt)\n",
    "#     if i > 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95761562-87a8-430a-af06-43e8926a75fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:50.635718Z",
     "iopub.status.busy": "2023-11-20T17:29:50.635609Z",
     "iopub.status.idle": "2023-11-20T17:29:53.298941Z",
     "shell.execute_reply": "2023-11-20T17:29:53.298495Z",
     "shell.execute_reply.started": "2023-11-20T17:29:50.635709Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022083100004, 2022083100005]\n"
     ]
    }
   ],
   "source": [
    "dataId = {\"instrument\": \"LATISS\"}\n",
    "outside_embargo = [\n",
    "        dt.id\n",
    "        for dt in registry.queryDimensionRecords(\n",
    "            \"exposure\",\n",
    "            dataId=dataId,\n",
    "            datasets=datasettype,\n",
    "            collections=collections,\n",
    "            where=\"NOT exposure.timespan OVERLAPS\\\n",
    "                                                    timespan_embargo\",\n",
    "            bind={\"timespan_embargo\": timespan_embargo},\n",
    "        )\n",
    "    ][0:2]\n",
    "print(outside_embargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc9f8ad1-cf0b-41c8-b97c-72c8273ee225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.299657Z",
     "iopub.status.busy": "2023-11-20T17:29:53.299525Z",
     "iopub.status.idle": "2023-11-20T17:29:53.314182Z",
     "shell.execute_reply": "2023-11-20T17:29:53.313822Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.299645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Query the DataIds after embargo period\n",
    "datasetRefs = registry.queryDatasets(\n",
    "    datasettype,\n",
    "    dataId=dataId,\n",
    "    collections=collections,\n",
    "    where=\"exposure.id IN (exposure_ids)\",\n",
    "    bind={\"exposure_ids\": outside_embargo},\n",
    ")#.expanded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e874080a-9669-4f9a-929f-d4803f22fdfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.314809Z",
     "iopub.status.busy": "2023-11-20T17:29:53.314682Z",
     "iopub.status.idle": "2023-11-20T17:29:53.322091Z",
     "shell.execute_reply": "2023-11-20T17:29:53.321742Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.314798Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...} [sc=Exposure] (run=LATISS/raw/all id=cfd59ff4-4991-5093-b499-b3aff2d2089c)\n",
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...} [sc=Exposure] (run=LATISS/raw/all id=d8975b39-6873-53e0-aa7f-d8781ceaaec7)\n"
     ]
    }
   ],
   "source": [
    "for ref in datasetRefs:\n",
    "    print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5b2043-da77-465c-b827-23eb94334186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.322699Z",
     "iopub.status.busy": "2023-11-20T17:29:53.322580Z",
     "iopub.status.idle": "2023-11-20T17:29:53.374296Z",
     "shell.execute_reply": "2023-11-20T17:29:53.373821Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.322688Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_prefix = '/home/j/jarugula/dest_uri' \n",
    "os.system('rm -rf '+dest_prefix)\n",
    "os.system('mkdir '+dest_prefix)\n",
    "dest_uri = lsst.resources.ResourcePath(dest_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae14f7e7-2e1c-4373-a485-73396c1ffa17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.375119Z",
     "iopub.status.busy": "2023-11-20T17:29:53.374987Z",
     "iopub.status.idle": "2023-11-20T17:29:53.377968Z",
     "shell.execute_reply": "2023-11-20T17:29:53.377629Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.375106Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResourcePath(\"file:///home/j/jarugula/dest_uri/\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14050c8-a4a3-4c08-b6ff-20e6b137e771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.378597Z",
     "iopub.status.busy": "2023-11-20T17:29:53.378482Z",
     "iopub.status.idle": "2023-11-20T17:29:53.390471Z",
     "shell.execute_reply": "2023-11-20T17:29:53.390099Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.378586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}, run='LATISS/raw/all', id=cfd59ff4-4991-5093-b499-b3aff2d2089c): DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), {}), DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, run='LATISS/raw/all', id=d8975b39-6873-53e0-aa7f-d8781ceaaec7): DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"), {})}\n"
     ]
    }
   ],
   "source": [
    "source_uri = butler.get_many_uris(datasetRefs)\n",
    "#source_uri = butler.getURI(datasetRefs)\n",
    "print(source_uri)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e26dbc9c-5180-403c-bfac-f0a347ce1315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T01:53:04.272581Z",
     "iopub.status.busy": "2023-11-11T01:53:04.272397Z",
     "iopub.status.idle": "2023-11-11T01:53:04.415622Z",
     "shell.execute_reply": "2023-11-11T01:53:04.415283Z",
     "shell.execute_reply.started": "2023-11-11T01:53:04.272569Z"
    },
    "tags": []
   },
   "source": [
    "for (key, value) in source_uri.items():\n",
    "    print(key)\n",
    "    # print(value.count)\n",
    "    # print(value.index)\n",
    "    source_path_uri = value[0]\n",
    "    print(source_path_uri)\n",
    "    print(source_path_uri.exists())\n",
    "    source_path = value[0].path.strip('/')\n",
    "    print(source_path)\n",
    "    print(value[0].relative_to(value[0].root_uri()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88820e5-3b24-4600-bcdb-ba1253da2927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.391125Z",
     "iopub.status.busy": "2023-11-20T17:29:53.391003Z",
     "iopub.status.idle": "2023-11-20T17:29:53.789391Z",
     "shell.execute_reply": "2023-11-20T17:29:53.788953Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.391114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "True\n",
      "LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "file:///home/j/jarugula/dest_uri/\n",
      "file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "True\n",
      "LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "file:///home/j/jarugula/dest_uri/\n",
      "file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n"
     ]
    }
   ],
   "source": [
    "filedataset_list = []\n",
    "for (key, value) in source_uri.items():\n",
    "    # print(key)\n",
    "    # print(value.count)\n",
    "    # print(value.index)\n",
    "    source_path_uri = value[0]\n",
    "    print(source_path_uri)\n",
    "    print(source_path_uri.exists())\n",
    "    # source_path = value[0].path.strip('/')\n",
    "    source_path = source_path_uri.relative_to(value[0].root_uri())\n",
    "    print(source_path)\n",
    "    print(dest_uri)\n",
    "    new_dest_uri = dest_uri.join(source_path)\n",
    "    print(new_dest_uri)\n",
    "    \n",
    "    # transfer \n",
    "    new_dest_uri.transfer_from(source_path_uri, transfer='copy')\n",
    "    \n",
    "    # make filedatasets for ingest\n",
    "    filedataset_list.append(lsst.daf.butler.FileDataset(new_dest_uri, key))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc3dfbd-5e25-413b-96d5-53c3ad7a5da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:53.790118Z",
     "iopub.status.busy": "2023-11-20T17:29:53.789997Z",
     "iopub.status.idle": "2023-11-20T17:29:53.792949Z",
     "shell.execute_reply": "2023-11-20T17:29:53.792596Z",
     "shell.execute_reply.started": "2023-11-20T17:29:53.790107Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FileDataset(refs=[DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}, run='LATISS/raw/all', id=cfd59ff4-4991-5093-b499-b3aff2d2089c)], path=ResourcePath(\"file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), formatter=None),\n",
       " FileDataset(refs=[DatasetRef(DatasetType('raw', {band, instrument, detector, physical_filter, exposure}, Exposure), {instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, run='LATISS/raw/all', id=d8975b39-6873-53e0-aa7f-d8781ceaaec7)], path=ResourcePath(\"file:///home/j/jarugula/dest_uri/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"), formatter=None)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filedataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ecc276d-0928-4284-a1be-cb0e27563209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:55.856432Z",
     "iopub.status.busy": "2023-11-20T17:29:55.855915Z",
     "iopub.status.idle": "2023-11-20T17:29:55.870107Z",
     "shell.execute_reply": "2023-11-20T17:29:55.869738Z",
     "shell.execute_reply.started": "2023-11-20T17:29:55.856418Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from prep_transfer import prep_for_ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c31f36e-2318-4f23-9bf0-2c16120f6e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:29:56.265112Z",
     "iopub.status.busy": "2023-11-20T17:29:56.264960Z",
     "iopub.status.idle": "2023-11-20T17:29:56.279776Z",
     "shell.execute_reply": "2023-11-20T17:29:56.279406Z",
     "shell.execute_reply.started": "2023-11-20T17:29:56.265099Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required dataset types are known to the target Butler\n",
      "All required collections are known to the target Butler\n"
     ]
    }
   ],
   "source": [
    "_ = prep_for_ingest(dest_registry, dest_butler, \n",
    "                    registry, butler, \n",
    "                    datasetRefs,\n",
    "                    register_dataset_types = False, \n",
    "                    register_collection = False,\n",
    "                    transfer_dimensions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "368a7814-c795-4b91-9d49-dbff94b97a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:30:17.349530Z",
     "iopub.status.busy": "2023-11-20T17:30:17.349277Z",
     "iopub.status.idle": "2023-11-20T17:30:17.733058Z",
     "shell.execute_reply": "2023-11-20T17:30:17.732640Z",
     "shell.execute_reply.started": "2023-11-20T17:30:17.349517Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_butler.ingest(*filedataset_list, transfer = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c631591-868e-4d3b-8a09-63498f447c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:31:36.060645Z",
     "iopub.status.busy": "2023-11-20T17:31:36.060358Z",
     "iopub.status.idle": "2023-11-20T17:31:36.065010Z",
     "shell.execute_reply": "2023-11-20T17:31:36.064624Z",
     "shell.execute_reply.started": "2023-11-20T17:31:36.060632Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetRefs = dest_registry.queryDatasets(\n",
    "    datasettype,\n",
    "    dataId=dataId,\n",
    "    collections=collections,\n",
    ")#.expanded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b32b7419-059b-47b3-aa6c-bee5fdb3b59a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:31:47.898491Z",
     "iopub.status.busy": "2023-11-20T17:31:47.898302Z",
     "iopub.status.idle": "2023-11-20T17:31:47.903947Z",
     "shell.execute_reply": "2023-11-20T17:31:47.903552Z",
     "shell.execute_reply.started": "2023-11-20T17:31:47.898478Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...} [sc=Exposure] (run=LATISS/raw/all id=cfd59ff4-4991-5093-b499-b3aff2d2089c)\n",
      "raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...} [sc=Exposure] (run=LATISS/raw/all id=d8975b39-6873-53e0-aa7f-d8781ceaaec7)\n"
     ]
    }
   ],
   "source": [
    "for ref in datasetRefs:\n",
    "    print(ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507f36e-ffd2-40ab-84f7-5c4ed96e29fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc551bc-c8f0-4b0f-b7e8-ef49a0d8d9d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:55:44.454244Z",
     "iopub.status.busy": "2023-11-16T19:55:44.453932Z",
     "iopub.status.idle": "2023-11-16T19:55:44.462469Z",
     "shell.execute_reply": "2023-11-16T19:55:44.461985Z",
     "shell.execute_reply.started": "2023-11-16T19:55:44.454228Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_for_ingest(target_registry, target_butler, \n",
    "                    source_registry, source_butler, \n",
    "                    source_refs, \n",
    "                    register_dataset_types = True, \n",
    "                    register_collection = True,\n",
    "                    transfer_dimensions=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    this code is taken from: \n",
    "    https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py\n",
    "    L1920-L1949\n",
    "    \n",
    "    This code registers DatasetType and collection to the target_butler.\n",
    "    Does not register instrument\n",
    "    \n",
    "    Run this code before ingest\n",
    "    \"\"\"\n",
    "    \n",
    "    # register datasetType\n",
    "    source_dataset_types = set()\n",
    "    for ref in source_refs:\n",
    "        source_dataset_types.add(ref.datasetType)\n",
    "        \n",
    "    newly_registered_dataset_types = set() \n",
    "    for datasetType in source_dataset_types:\n",
    "        if register_dataset_types:\n",
    "            if target_registry.registerDatasetType(datasetType):\n",
    "                newly_registered_dataset_types.add(datasetType)\n",
    "        else:\n",
    "            # If the dataset type is missing, let it fail immediately.\n",
    "            target_dataset_type = target_registry.getDatasetType(datasetType.name)\n",
    "            # print(target_dataset_type)\n",
    "            if target_dataset_type != datasetType:\n",
    "                raise ConflictingDefinitionError(\n",
    "                    \"Source butler dataset type differs from definition\"\n",
    "                    f\" in target butler: {datasetType} !=\"\n",
    "                    f\" {target_dataset_type}\"\n",
    "                )\n",
    "                \n",
    "    if newly_registered_dataset_types:\n",
    "        print( \"Registered the following dataset types in the target Butler: \",\n",
    "              \", \".join(d.name for d in newly_registered_dataset_types),\n",
    "             )\n",
    "    else:\n",
    "        print(\"All required dataset types are known to the target Butler\")\n",
    "        \n",
    "    # register collection\n",
    "    # This is written only for run collection\n",
    "    source_collection = set()\n",
    "    for ref in source_refs:\n",
    "        source_collection.add(ref.run)\n",
    "        \n",
    "    newly_registered_collection = set() \n",
    "    for collection in source_collection:\n",
    "        if register_collection:\n",
    "            collection_type = source_registry.getCollectionType(collection)\n",
    "            if target_registry.registerCollection(collection, CollectionType(collection_type)):\n",
    "                newly_registered_collection.add(collection)\n",
    "                \n",
    "        else:\n",
    "            target_collection = target_registry.getCollectionSummary(collection)\n",
    "            if target_collection != source_registry.getCollectionSummary(collection):\n",
    "                raise ConflictingDefinitionError(\n",
    "                    \"Source butler collection differs from definition\"\n",
    "                    f\" in target butler: {collection} !=\"\n",
    "                    f\" {target_collection}\"\n",
    "                )\n",
    "                                \n",
    "    if newly_registered_collection:\n",
    "        print( \"Registered the following collection in the target Butler: \",\n",
    "              \", \".join(collection for collection in newly_registered_collection),\n",
    "             )\n",
    "    else:\n",
    "        print(\"All required collections are known to the target Butler\")\n",
    "    \n",
    "        \n",
    "    dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "    if transfer_dimensions:\n",
    "        elements = frozenset(\n",
    "                element\n",
    "                for element in target_butler.dimensions.getStaticElements()\n",
    "                if element.hasTable() and element.viewOf is None\n",
    "            )\n",
    "        dataIds = {ref.dataId for ref in source_refs}\n",
    "        \n",
    "        for dataId in dataIds:\n",
    "            if not dataId.hasRecords():\n",
    "                if registry := getattr(source_butler, \"registry\", None):\n",
    "                    dataId = source_registry.expandDataId(dataId)\n",
    "                else:\n",
    "                    raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "            for record in dataId.records.values():\n",
    "                if record is not None and record.definition in elements:\n",
    "                    dimension_records[record.definition].setdefault(record.dataId, record)\n",
    "                    \n",
    "        print('dimension records after', dimension_records)\n",
    "        \n",
    "        print(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "        for element, r in dimension_records.items():\n",
    "            records = [r[dataId] for dataId in r]\n",
    "            dest_butler._registry.insertDimensionData(element, *records, skip_existing=True)\n",
    "        \n",
    "    return _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3085589b-389b-47f7-ad77-893a8734a80a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:55:45.785802Z",
     "iopub.status.busy": "2023-11-16T19:55:45.785522Z",
     "iopub.status.idle": "2023-11-16T19:55:45.794821Z",
     "shell.execute_reply": "2023-11-16T19:55:45.794420Z",
     "shell.execute_reply.started": "2023-11-16T19:55:45.785789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required dataset types are known to the target Butler\n",
      "All required collections are known to the target Butler\n"
     ]
    }
   ],
   "source": [
    "_ = prep_for_ingest(dest_registry, dest_butler, \n",
    "                    registry, butler, \n",
    "                    datasetRefs,\n",
    "                    register_dataset_types = False, \n",
    "                    register_collection = False,\n",
    "                    transfer_dimensions = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52c2090c-51ec-48d7-a012-9846a9c5ffe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:55:47.211205Z",
     "iopub.status.busy": "2023-11-16T19:55:47.210911Z",
     "iopub.status.idle": "2023-11-16T19:55:47.592493Z",
     "shell.execute_reply": "2023-11-16T19:55:47.592060Z",
     "shell.execute_reply.started": "2023-11-16T19:55:47.211189Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ingest to the destination butler\n",
    "dest_butler.ingest(*filedataset_list, transfer = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e609d956-5ef3-4198-91e6-4b2591718efc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-20T17:30:38.894691Z",
     "iopub.status.busy": "2023-11-20T17:30:38.894210Z",
     "iopub.status.idle": "2023-11-20T17:30:38.903936Z",
     "shell.execute_reply": "2023-11-20T17:30:38.903532Z",
     "shell.execute_reply.started": "2023-11-20T17:30:38.894677Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results [exposure.RecordClass(instrument='LATISS', id=2022083100004, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000004', exposure_time=0.0, dark_time=0.0160482, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=4, seq_start=4, seq_end=4, group_name='2022083100004', group_id=2022083100004, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:58:13.633984', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:58:13.650000', scale='tai', format='iso'))), exposure.RecordClass(instrument='LATISS', id=2022083100005, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000005', exposure_time=0.0, dark_time=0.011363, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=5, seq_start=5, seq_end=5, group_name='2022083100005', group_id=2022083100005, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:59:03.162020', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:59:03.173000', scale='tai', format='iso')))]\n"
     ]
    }
   ],
   "source": [
    "results = dest_registry.queryDimensionRecords( 'exposure',\n",
    "                                                 collections='LATISS/raw/all',\n",
    "                                                 datasets='raw')\n",
    "results = list( set(results) )\n",
    "print('results', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1ccad-f4ed-43ee-b2ae-8a55b913446f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4955708-e075-4943-9f1d-414ed05a6a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5fc11-0d11-4ca7-9d7a-40af761e19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8376996-ebe0-473c-b3b6-51856247a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6892defc-45b5-43ea-a870-f8c2ce9d7730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "45ea5354-3403-4010-9d42-5a560c4ef494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T17:19:40.850727Z",
     "iopub.status.busy": "2023-11-16T17:19:40.850443Z",
     "iopub.status.idle": "2023-11-16T17:19:41.017182Z",
     "shell.execute_reply": "2023-11-16T17:19:41.016716Z",
     "shell.execute_reply.started": "2023-11-16T17:19:40.850714Z"
    },
    "tags": []
   },
   "source": [
    "# before we can run ingest, we need to register everything:\n",
    "# this code is taken from: https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py#L1920-L1949\n",
    "\n",
    "# Check to see if the dataset type in the source butler has\n",
    "# the same definition in the target butler and register missing\n",
    "# ones if requested. Registration must happen outside a transaction.\n",
    "newly_registered_dataset_types = set()\n",
    "for datasetType in source_dataset_types:\n",
    "    if register_dataset_types:\n",
    "        # Let this raise immediately if inconsistent. Continuing\n",
    "        # on to find additional inconsistent dataset types\n",
    "        # might result in additional unwanted dataset types being\n",
    "        # registered.\n",
    "        if dest_registry.registerDatasetType(datasetType):\n",
    "            newly_registered_dataset_types.add(datasetType)\n",
    "    else:\n",
    "        # If the dataset type is missing, let it fail immediately.\n",
    "        target_dataset_type = dest_registry.getDatasetType(datasetType.name)\n",
    "        if target_dataset_type != datasetType:\n",
    "            raise ConflictingDefinitionError(\n",
    "                \"Source butler dataset type differs from definition\"\n",
    "                f\" in target butler: {datasetType} !=\"\n",
    "                f\" {target_dataset_type}\"\n",
    "            )\n",
    "if newly_registered_dataset_types:\n",
    "    # We may have registered some even if there were inconsistencies\n",
    "    # but should let people know (or else remove them again).\n",
    "    _LOG.verbose(\n",
    "        \"Registered the following dataset types in the target Butler: %s\",\n",
    "        \", \".join(d.name for d in newly_registered_dataset_types),\n",
    "    )\n",
    "else:\n",
    "    _LOG.verbose(\"All required dataset types are known to the target Butler\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5caa1b31-9393-434e-9b12-6523b43e713e",
   "metadata": {},
   "source": [
    "# and this is from https://github.com/lsst/daf_butler/blob/1e3d68c2a155215c755c62404ea5fdd1de110740/python/lsst/daf/butler/direct_butler.py#L1951-L1975\n",
    "dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "if transfer_dimensions:\n",
    "    # Collect all the dimension records for these refs.\n",
    "    # All dimensions are to be copied but the list of valid dimensions\n",
    "    # come from this butler's universe.\n",
    "    elements = frozenset(\n",
    "        element\n",
    "        for element in self.dimensions.getStaticElements()\n",
    "        if element.hasTable() and element.viewOf is None\n",
    "    )\n",
    "    dataIds = {ref.dataId for ref in source_refs}\n",
    "    # This logic comes from saveDataIds.\n",
    "    for dataId in dataIds:\n",
    "        # Need an expanded record, if not expanded that we need a full\n",
    "        # butler with registry (allow mocks with registry too).\n",
    "        if not dataId.hasRecords():\n",
    "            if registry := getattr(source_butler, \"registry\", None):\n",
    "                dataId = registry.expandDataId(dataId)\n",
    "            else:\n",
    "                raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "        # If this butler doesn't know about a dimension in the source\n",
    "        # butler things will break later.\n",
    "        for record in dataId.records.values():\n",
    "            if record is not None and record.definition in elements:\n",
    "                dimension_records[record.definition].setdefault(record.dataId, record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afc89b46-35a6-49e1-9ae0-18c8bd81ae2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:52:57.002986Z",
     "iopub.status.busy": "2023-11-15T17:52:57.002669Z",
     "iopub.status.idle": "2023-11-15T17:52:57.017938Z",
     "shell.execute_reply": "2023-11-15T17:52:57.017517Z",
     "shell.execute_reply.started": "2023-11-15T17:52:57.002973Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension records before defaultdict(<class 'dict'>, {})\n",
      "frozenset({DatabaseDimension(exposure), DatabaseDimension(subfilter), DatabaseDimension(patch), DatabaseDimensionCombination(visit_system_membership), DatabaseDimension(detector), DatabaseDimension(tract), GovernorDimension(instrument), DatabaseDimension(physical_filter), DatabaseDimensionCombination(visit_detector_region), GovernorDimension(skymap), DatabaseDimension(visit), DatabaseDimensionCombination(visit_definition), DatabaseDimension(visit_system)})\n",
      "dataIds {{instrument: 'LATISS', detector: 0, exposure: 2022083100005, ...}, {instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...}}\n",
      "dimension records after defaultdict(<class 'dict'>, {GovernorDimension(instrument): {{instrument: 'LATISS'}: instrument.RecordClass(name='LATISS', visit_max=6050123199999, visit_system=2, exposure_max=6050123199999, detector_max=1, class_name='lsst.obs.lsst.Latiss')}, DatabaseDimension(detector): {{instrument: 'LATISS', detector: 0}: detector.RecordClass(instrument='LATISS', id=0, full_name='RXX_S00', name_in_raft='RXX_S00', raft=None, purpose='SCIENCE')}, DatabaseDimension(physical_filter): {{instrument: 'LATISS', physical_filter: 'unknown~unknown'}: physical_filter.RecordClass(instrument='LATISS', name='unknown~unknown', band='unknown')}, DatabaseDimension(exposure): {{instrument: 'LATISS', exposure: 2022083100005}: exposure.RecordClass(instrument='LATISS', id=2022083100005, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000005', exposure_time=0.0, dark_time=0.011363, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=5, seq_start=5, seq_end=5, group_name='2022083100005', group_id=2022083100005, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:59:03.162020', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:59:03.173000', scale='tai', format='iso'))), {instrument: 'LATISS', exposure: 2022083100004}: exposure.RecordClass(instrument='LATISS', id=2022083100004, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000004', exposure_time=0.0, dark_time=0.0160482, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=4, seq_start=4, seq_end=4, group_name='2022083100004', group_id=2022083100004, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:58:13.633984', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:58:13.650000', scale='tai', format='iso')))}})\n"
     ]
    }
   ],
   "source": [
    "# re-defining stuff to align with the butler code:\n",
    "source_refs = datasetRefs\n",
    "source_butler = butler\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from lsst.daf.butler import (\n",
    "    DataCoordinate,\n",
    "    DataId,\n",
    "    DataIdValue,\n",
    "    Dimension,\n",
    "    DimensionElement,\n",
    "    DimensionRecord,\n",
    "    DimensionUniverse,\n",
    ")\n",
    "\n",
    "dimension_records: dict[DimensionElement, dict[DataCoordinate, DimensionRecord]] = defaultdict(dict)\n",
    "print('dimension records before', dimension_records)\n",
    "\n",
    "elements = frozenset(\n",
    "                element\n",
    "                for element in dest_butler.dimensions.getStaticElements()\n",
    "                if element.hasTable() and element.viewOf is None\n",
    "            )\n",
    "print(elements)\n",
    "\n",
    "dataIds = {ref.dataId for ref in source_refs}\n",
    "print('dataIds', dataIds)\n",
    "\n",
    "# This logic comes from saveDataIds.\n",
    "for dataId in dataIds:\n",
    "    # Need an expanded record, if not expanded that we need a full\n",
    "    # butler with registry (allow mocks with registry too).\n",
    "    if not dataId.hasRecords():\n",
    "        if registry := getattr(source_butler, \"registry\", None):\n",
    "            dataId = registry.expandDataId(dataId)\n",
    "        else:\n",
    "            raise TypeError(\"Input butler needs to be a full butler to expand DataId.\")\n",
    "    # If this butler doesn't know about a dimension in the source\n",
    "    # butler things will break later.\n",
    "    for record in dataId.records.values():\n",
    "        if record is not None and record.definition in elements:\n",
    "            dimension_records[record.definition].setdefault(record.dataId, record)\n",
    "print('dimension records after', dimension_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b3da80b-760e-4040-8625-c0f18090fd37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T17:55:09.260680Z",
     "iopub.status.busy": "2023-11-15T17:55:09.260235Z",
     "iopub.status.idle": "2023-11-15T17:55:09.293103Z",
     "shell.execute_reply": "2023-11-15T17:55:09.292722Z",
     "shell.execute_reply.started": "2023-11-15T17:55:09.260663Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensuring that dimension records exist for transferred datasets.\n"
     ]
    }
   ],
   "source": [
    "# now actually do the mod of dimension records\n",
    "if dimension_records:\n",
    "    #_LOG.verbose(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "    print(\"Ensuring that dimension records exist for transferred datasets.\")\n",
    "    for element, r in dimension_records.items():\n",
    "        records = [r[dataId] for dataId in r]\n",
    "        # Assume that if the record is already present that we can\n",
    "        # use it without having to check that the record metadata\n",
    "        # is consistent.\n",
    "        dest_butler._registry.insertDimensionData(element, *records, skip_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ce27fd3-1135-4974-b524-c73d02cc7ac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-16T19:45:09.395146Z",
     "iopub.status.busy": "2023-11-16T19:45:09.394859Z",
     "iopub.status.idle": "2023-11-16T19:45:09.403982Z",
     "shell.execute_reply": "2023-11-16T19:45:09.403605Z",
     "shell.execute_reply.started": "2023-11-16T19:45:09.395130Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lsst.daf.butler._registry_shim.RegistryShim object at 0x7f361a038490>\n",
      "results [exposure.RecordClass(instrument='LATISS', id=2022083100005, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000005', exposure_time=0.0, dark_time=0.011363, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=5, seq_start=5, seq_end=5, group_name='2022083100005', group_id=2022083100005, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:59:03.162020', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:59:03.173000', scale='tai', format='iso'))), exposure.RecordClass(instrument='LATISS', id=2022083100004, physical_filter='unknown~unknown', obs_id='AT_O_20220831_000004', exposure_time=0.0, dark_time=0.0160482, observation_type='bias', observation_reason='bias', day_obs=20220831, seq_num=4, seq_start=4, seq_end=4, group_name='2022083100004', group_id=2022083100004, target_name='UNKNOWN', science_program='unknown', tracking_ra=None, tracking_dec=None, sky_angle=None, azimuth=None, zenith_angle=None, has_simulated=False, timespan=Timespan(begin=astropy.time.Time('2022-08-31 22:58:13.633984', scale='tai', format='iso'), end=astropy.time.Time('2022-08-31 22:58:13.650000', scale='tai', format='iso')))]\n"
     ]
    }
   ],
   "source": [
    "# test dimensionrecord\n",
    "print(dest_registry)\n",
    "\n",
    "results = dest_registry.queryDimensionRecords( 'exposure',\n",
    "                                                 collections='LATISS/raw/all',\n",
    "                                                 datasets='raw')\n",
    "results = list( set(results) )\n",
    "print('results', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eec2fd-ce6e-4f67-ac0f-9f092a778fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pipelines.lsst.io/v/daily/py-api/lsst.daf.butler.Registry.html#lsst.daf.butler.Registry.queryDimensionRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e6567ea-1841-4c23-8c91-3eee86167920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-11T02:00:59.749863Z",
     "iopub.status.busy": "2023-11-11T02:00:59.749654Z",
     "iopub.status.idle": "2023-11-11T02:00:59.764222Z",
     "shell.execute_reply": "2023-11-11T02:00:59.763534Z",
     "shell.execute_reply.started": "2023-11-11T02:00:59.749847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RegistryShim.syncDimensionData() missing 2 required positional arguments: 'element' and 'row'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdest_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msyncDimensionData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: RegistryShim.syncDimensionData() missing 2 required positional arguments: 'element' and 'row'"
     ]
    }
   ],
   "source": [
    "dest_registry.syncDimensionData()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a5a5a-46bc-439c-9e77-2d24d2c1c8b0",
   "metadata": {},
   "source": [
    "Use datasetRefs to look up the URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755761cb-01d7-4eed-84df-8d0c3ab6dbca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dest_uri.join(LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits)\n",
    "# dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "# dest_uri = dest_prefix + 'LATISS'\n",
    "# dest = Butler(dest_prefix, writeable=True)\n",
    "\n",
    "#dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02f1bbce-14e8-4a42-ae73-c8a88bc08697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:55:43.508351Z",
     "iopub.status.busy": "2023-10-23T20:55:43.508101Z",
     "iopub.status.idle": "2023-10-23T20:55:43.522877Z",
     "shell.execute_reply": "2023-10-23T20:55:43.522396Z",
     "shell.execute_reply.started": "2023-10-23T20:55:43.508336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key raw@{instrument: 'LATISS', detector: 0, exposure: 2022083100004, ...} [sc=Exposure] (run=LATISS/raw/all id=cfd59ff4-4991-5093-b499-b3aff2d2089c) value DatasetRefURIs(ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), {})\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DatasetRefURIs' object has no attribute 'as_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m source_uri\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m, key,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, value)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_local\u001b[49m())\n\u001b[1;32m      5\u001b[0m STOP\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(source_uri\u001b[38;5;241m.\u001b[39mkeys())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DatasetRefURIs' object has no attribute 'as_local'"
     ]
    }
   ],
   "source": [
    "#for i, (key, value) in enumerate(my_dict.items()):\n",
    "for (key, value) in source_uri.items():\n",
    "    print('key', key,'value', value)\n",
    "    print(value.as_local())\n",
    "    \n",
    "STOP\n",
    "print(source_uri.keys())\n",
    "print(source_uri[0].exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d2561-c6b0-4fb0-ab7c-8e300a9d8fd5",
   "metadata": {},
   "source": [
    "The below cell is failing because transfer_from is expecting a dict object from source_uri that has an as_local() element. When we obtain the source_uri list, there is an empty element for the component URI, but I'm not sure if this is the root of the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1e7020e1-3da8-4665-a611-b56baf07d4f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:56:46.963550Z",
     "iopub.status.busy": "2023-10-23T20:56:46.963300Z",
     "iopub.status.idle": "2023-10-23T20:56:46.989140Z",
     "shell.execute_reply": "2023-10-23T20:56:46.988682Z",
     "shell.execute_reply.started": "2023-10-23T20:56:46.963537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'as_local'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# we need dest_uri to not be a string\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# and to actually be \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdest_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransfer_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dest\u001b[38;5;241m.\u001b[39mingest(datasetRefs, mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirect\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/resources/g24611a4c00+e358f92434/python/lsst/resources/file.py:169\u001b[0m, in \u001b[0;36mFileResourcePath.transfer_from\u001b[0;34m(self, src, transfer, overwrite, transaction)\u001b[0m\n\u001b[1;32m    158\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransferring \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [exists: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] -> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [exists: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m] (transfer=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    160\u001b[0m         src,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m         transfer,\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# We do not have to special case FileResourcePath here because\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# as_local handles that.\u001b[39;00m\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_local\u001b[49m() \u001b[38;5;28;01mas\u001b[39;00m local_uri:\n\u001b[1;32m    170\u001b[0m     is_temporary \u001b[38;5;241m=\u001b[39m local_uri\u001b[38;5;241m.\u001b[39misTemporary\n\u001b[1;32m    171\u001b[0m     local_src \u001b[38;5;241m=\u001b[39m local_uri\u001b[38;5;241m.\u001b[39mospath\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'as_local'"
     ]
    }
   ],
   "source": [
    "\n",
    "# we need dest_uri to not be a string\n",
    "# and to actually be \n",
    "dest_uri.transfer_from(source_uri, transfer='copy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24ccd655-26e2-4845-b7cd-25eb934b75fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T21:07:40.021065Z",
     "iopub.status.busy": "2023-10-23T21:07:40.020888Z",
     "iopub.status.idle": "2023-10-23T21:07:40.045772Z",
     "shell.execute_reply": "2023-10-23T21:07:40.045285Z",
     "shell.execute_reply.started": "2023-10-23T21:07:40.021053Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ParentDatasetQueryResults' object has no attribute 'refs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mingest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatasetRefs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, mode = 'direct')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/daf_butler/gfc0b858265+07967ebf72/python/lsst/daf/butler/core/utils.py:61\u001b[0m, in \u001b[0;36mtransactional.<locals>.inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransaction():\n\u001b[0;32m---> 61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/lsst/software/stack/stack/miniconda3-py38_4.9.2-7.0.1/Linux64/daf_butler/gfc0b858265+07967ebf72/python/lsst/daf/butler/_butler.py:2023\u001b[0m, in \u001b[0;36mButler.ingest\u001b[0;34m(self, transfer, run, idGenerationMode, record_validation_info, *datasets)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m progress\u001b[38;5;241m.\u001b[39mwrap(datasets, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrouping by dataset type\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;66;03m# Somewhere to store pre-existing refs if we have an\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m# execution butler.\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m     existingRefs: \u001b[38;5;28mlist\u001b[39m[DatasetRef] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2023\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ref \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefs\u001b[49m:\n\u001b[1;32m   2024\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m ref\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# For mypy\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m         group_key \u001b[38;5;241m=\u001b[39m (ref\u001b[38;5;241m.\u001b[39mdatasetType, ref\u001b[38;5;241m.\u001b[39mrun)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ParentDatasetQueryResults' object has no attribute 'refs'"
     ]
    }
   ],
   "source": [
    "# next do ingest\n",
    "# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "dest.ingest(datasetRefs)#, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69081372-a768-47fc-b33b-8442c35360b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dee2383-d431-44de-bb96-e4c0672eec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa78d3e3-2a19-468b-9e97-c1da8eec6cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d99624d0-bfa9-404f-bc44-d4d827e9f0e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:41:07.108669Z",
     "iopub.status.busy": "2023-10-20T19:41:07.108390Z",
     "iopub.status.idle": "2023-10-20T19:41:07.116799Z",
     "shell.execute_reply": "2023-10-20T19:41:07.116409Z",
     "shell.execute_reply.started": "2023-10-20T19:41:07.108655Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lsst.resources.s3.S3ResourcePath'> s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\n",
      "<class 'lsst.resources.s3.S3ResourcePath'> s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\n",
      "[ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000004/AT_O_20220831_000004_R00_S00.fits\"), ResourcePath(\"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\")]\n"
     ]
    }
   ],
   "source": [
    "uri_list = []\n",
    "for i,ref in enumerate(datasetRefs):\n",
    "    #print(ref.dataId.full)\n",
    "    uri = butler.getURI(ref)\n",
    "    print(type(uri), uri)\n",
    "    uri_list.append(uri)\n",
    "print(uri_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5169df6-1325-4b31-b700-abea4b66f86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:33:26.604893Z",
     "iopub.status.busy": "2023-10-20T19:33:26.604486Z",
     "iopub.status.idle": "2023-10-20T19:33:26.691862Z",
     "shell.execute_reply": "2023-10-20T19:33:26.691507Z",
     "shell.execute_reply.started": "2023-10-20T19:33:26.604876Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dest_prefix = '/home/r/rnevin/scratch'\n",
    "dest = Butler(dest_prefix, writeable=True)\n",
    "dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc7635d1-55b7-4cad-ac2c-3d53be37d02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T19:41:35.805930Z",
     "iopub.status.busy": "2023-10-20T19:41:35.805463Z",
     "iopub.status.idle": "2023-10-20T19:41:35.817273Z",
     "shell.execute_reply": "2023-10-20T19:41:35.816873Z",
     "shell.execute_reply.started": "2023-10-20T19:41:35.805915Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"list\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlsst\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#uri = \"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m uri_src \u001b[38;5;241m=\u001b[39m lsst\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mResourcePath\u001b[38;5;241m.\u001b[39mtransfer_from(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/repo/embargo/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muri_list\u001b[49m, transfer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(uri_src)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# next do ingest\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"list\") to str"
     ]
    }
   ],
   "source": [
    "import lsst\n",
    "#uri = \"s3://rubin-summit/LATISS/20220831/AT_O_20220831_000005/AT_O_20220831_000005_R00_S00.fits\"\n",
    "uri_src = lsst.resources.ResourcePath.transfer_from('/repo/embargo/' + uri_list, transfer='copy')\n",
    "print(uri_src)\n",
    "\n",
    "# next do ingest\n",
    "# The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "# https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "dest.ingest(uri_src, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1590869-08f7-4df3-9392-de63e03b655c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f50fd-e8ea-4fe6-9efd-abbf1da0ecd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#butler = Butler('/repo/embargo')\n",
    "#registry = butler.registry\n",
    "\n",
    "dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "\n",
    "dest = Butler(dest_prefix + uri, writeable=True)\n",
    "dest_registry = dest.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc0a5e-94dd-484d-8c2f-38aab292d79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e7e21f7-e9f1-4ca8-8e46-e1edace8c0e4",
   "metadata": {},
   "source": [
    "lsst.resources.ResourcePath.transfer_from(src, transfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8bc56d-8c2e-479b-8dff-468f9290f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_prefix = '/sdf/data/rubin/lsstdata/offline/instrument/'\n",
    "\n",
    "dest = Butler(dest_prefix + uri, writeable=True)\n",
    "dest_registry = dest.registry\n",
    "\n",
    "for i,ref in enumerate(datasetRefs):\n",
    "    #print(ref.dataId.full)\n",
    "    uri = butler.getURI(ref)\n",
    "    print(uri)\n",
    "    # first do transfer_from\n",
    "    # https://pipelines.lsst.io/v/weekly/py-api/lsst.resources.ResourcePath.html\n",
    "    # actually, returns an URI with an updated final component of the source\n",
    "    uri_src = lsst.resources.ResourcePath.transfer_from('/repo/embargo/'+uri)\n",
    "\n",
    "    # next do ingest\n",
    "    # The ingestion should then be handled using butler.ingest() using the existing DatasetRef from /repo/embargo and the new (absolute) destination path, using transfer mode direct.\n",
    "    # https://pipelines.lsst.io/py-api/lsst.daf.butler.Butler.html#lsst.daf.butler.Butler.ingest\n",
    "    dest.ingest(uri_src, mode = 'direct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7b3b1-07e5-4418-90a2-38e81323b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dest.transfer_from(\n",
    "    butler,\n",
    "    source_refs=datasetRefs,\n",
    "    transfer=\"copy\",\n",
    "    skip_missing=True,\n",
    "    register_dataset_types=True,\n",
    "    transfer_dimensions=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f282eee-c95c-4815-ab52-28f1334fd53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
